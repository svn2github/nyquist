<html>
  <head>
    <title>Convolution Tutorial</title>
    <style>body {max-width: 40em}</style>
  </head>
  <body bgcolor="#FFFFFF">
    <h1>Convolution Tutorial</h1>
<h3>Extension name: <code>convolve</code></h3>
<p><i>This extension is a tutorial for convolution in Nyquist.</i>
<hr>
<!-- Version: 1.0; (version for extension metadata, do not change) -->
Author Name: Roger B. Dannenberg;<br>
Author Email: rbd@cs.cmu.edu;<br>
<br>
Additional File: convolve.sal;<br>
<!-- End Metadata -->
<hr>
<h2>Usage:</h2>
In SAL mode:
<blockquote>
<pre>
load "convolve/convolve"  ;; you must load the code before calling functions
exec convolve-demo-1()    ;; reverberation demo
exec convolve-demo-2()    ;; convolve tone with voice
</pre>
</blockquote>    <p><b>Roger B. Dannenberg</b></p>
    <p>This page describes how to use the convolution function in
      Nyquist. Convolution is used for filtering, reverberation, and
      combining sounds.<br>
    </p>
    <p>The convolution function is <tt>convolution</tt>, which is
      called as follows:<br>
    </p>
    <blockquote><tt>convolution(sound, response)<br>
      </tt></blockquote>
    where <tt>sound</tt> is the input sound, and <tt>response</tt> is
    the <i>impulse response</i>. These parameters will be explained
    further below.<br>
    <h2>How It Works</h2>
    <p>Convolution works by scaling and shifting the input signal
      according to the response signal. For example, consider a very
      simple example where the response has only two samples: 0.1, 0.2.
      In this case, the input sound is copied and scaled by 0.1 (with no
      shift). It is also copied, shifted by one sample, and scaled by
      0.2. Then, these two copies are added to form the result. <br>
    </p>
    <p>Now, consider a slightly more complex response consisting of 0.5,
      0, 0, 0, ..., 0, 0, 0.5. Let's assume there are 44,099, or about 1
      second's worth, of zeros, and only the first and last sample of
      the response are non-zero. The convolution algorithm is the same,
      only this time we'll make 44101 copies, shifting them by 0 to
      44100 samples, and all are scaled by zero except for the first and
      last copy, so we can ignore most of them. The interesting part
      then is that we get a copy of the sound scaled by 0.5 plus a copy
      of the sound scaled by 0.5 and shifted by 44100, resulting in a 1
      delay.<br>
    </p>
    <p>That's a lot of work to make a delay! But notice that if we
      changed more of the zeros to non-zero values, we could insert lots
      of delays, each with a different amplitude. Taken to an extreme --
      thousands of delays and scale factors, increasing in density -- we
      can describe reverberation. Reverberation can be viewed as a
      specific kind of filter. Convolution is a general way to create a
      wide variety of filters. In particular, convolution can implement
      any <i>finite impulse response,</i> or <i>FIR</i> filter.<br>
    </p>
    We have not really explained &ldquo;how it works&rdquo; yet. The convolution
    function in Nyquist uses an algorithm called &ldquo;fast convolution,&rdquo;
    which relies on the Fast Fourier Transform. While you might think
    that shifting and scaling M samples once for each of N response
    samples would take M x N operations, the fast convolution works much
    faster. If M and N are the same, fast convolution takes time
    proportional to only N log(N).&nbsp; In practice, if the input sound
    is long, convolution run time will be proportional to the length of
    the sound, but the sound is processed efficiently in blocks using
    fast convolution.<br>
    <h2> Example</h2>
    <p>A common application of convolution is reverberation. You can
      search the internet for downloadable impulse responses. You can
      also synthesize an impulse response from noise. Here is an example
      that models a short melody with reverberation created from
      convolution. Because the reverberation is based on noise, it is
      very smooth and uniform. Impulse responses based on real rooms (or
      even good room models) may have more &ldquo;character&rdquo; formed by early
      reflections and somewhat irregular reflection patterns.<br>
    </p>
    <p>In the code below, <tt>response</tt> is a function that computes
      a reverberation response -- in this case just an exponentially
      decaying noise signal. The <tt>melody</tt> function uses <tt>dhm-organ</tt>
      to make a short musical phrase. The <tt>convolve</tt> function
      convolves the melody with the reverb response to create a
      reverberated signal.<br>
    </p>
    <pre>load "mateos/organ.lsp" ;; defines dmhm-organ(pitch)

function response()
  return noise() * pwev(0.5, 1, 0.001)

function melody()
  return sim(dmhm-organ(c4) ~ 0.5 @ 0,
             dmhm-organ(bf3) ~ 0.4 @ 0.4,
             dmhm-organ(f3) ~ 0.5 @ 0.8,
             dmhm-organ(g4) ~ 1 @ 1.3)

function convolve-demo-1()
  play convolve(melody(), response() ~ 4)

exec convolve-demo-1()
    </pre>
    <p>The next example has no corollary in the acoustical world: We
      convolve a musical signal with a speech signal. You can hear
      traces of both inputs in the output. Convolution is symmetric, so
      you can think of this as either the musical signal reverberated in
      a room whose impulse response sounds like speech or a speech
      signal reverberated in a room whose impulse response sounds like
      music.<br>
    </p>
    <pre>function convolve-demo-2()
  play convolve(s-read("../audio/happy.wav"), 
                s-read("../audio/pv.wav"))

exec convolve-demo-2()
</pre>
    <p>Source code to run both of these examples is in <a
        href="convolve.sal"><tt>convolve.sal</tt></a>. </p>
  </body>
</html>

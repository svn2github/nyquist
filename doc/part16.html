<html><head><title>Nyquist Libraries</title>
<link rel="stylesheet" type="text/css" href="nyquiststyle.css">
<link rel="icon" href="nyquist-icon.png" />
<link rel="shortcut icon" href="nyquist-icon.png" />
</head>
<body bgcolor="ffffff">
<a href = "part15.html">Previous Section</a> | <a href = "part17.html">Next Section</a> | <a href = "title.html#toc">Table of Contents</a> | <a href = "indx.html">Index</a> | <a href = "title.html">Title Page</a>
<hr>
<a name = "181"><h2>Nyquist Libraries</h2></a>
<a name="index1278"></a>
Nyquist is always growing with new functions. Functions that are most fundamental
are added to the core language. These functions are automatically loaded when you 
start Nyquist, and they are documented in the preceding chapters. Other functions seem
less central and are implemented as lisp files that you can load. These are called
library functions, and they are described here. 
<p>
To use a library function, you
must first load the library, e.g. <code>(load "pianosyn")</code> loads the piano synthesis
library. The libraries are all located in the <code>lib</code> directory, and you 
should therefore include this directory on your <code>XLISPPATH</code> variable. (See 
Section .) Each library is documented in one of the following
sections. When you load the library described by the section, all functions
documented in that section become available.
<p>
<a name = "182"><h3>Statistics</h3></a>
<a name="index1279"></a><a name="index1280"></a><a name="index1281"></a><a name="index1282"></a><a name="index1283"></a><a name="index1284"></a><a name="index1285"></a><a name="index1286"></a><a name="index1287"></a><a name="index1288"></a><a name="index1289"></a><a name="index1290"></a><a name="index1291"></a><a name="index1292"></a>
The file <code>statistics.lsp</code> defines a class and functions to compute simple statistics, histograms, correlation, and some other tests. See the source code for complete details.
<p>
<a name = "183"><h3>Plots</h3></a>
<a name="index1293"></a><a name="index1294"></a>
The Nyquist IDE has a simple facility to plot signals. For more advanced plotting, you can use <code>gnuplot.sal</code> to generate plots for <code>gnuplot</code>, a separate, but free program. See the source for details.
<p>
<a name = "184"><h3>Labeling Audio Events, Marking Audio Times, Displaying Marked Audio Times</h3></a>
<a name="index1295"></a><a name="index1296"></a><a name="index1297"></a><a name="index1298"></a>
The <code>labels.sal</code> program can convert lists to label files and label files to lists. Label files can be loaded along with audio in Audacity to show metadata. See the source for details.
<p>
<a name = "185"><h3>Linear Regression</h3></a>
<a name="index1299"></a><a name="index1300"></a><a name="index1301"></a>
See <code>regression.sal</code> for simple linear regression functions.
<p>
<a name = "186"><h3>Vector Math, Linear Algebra</h3></a>
<a name="index1302"></a><a name="index1303"></a><a name="index1304"></a><a name="index1305"></a><a name="index1306"></a><a name="index1307"></a><a name="index1308"></a><a name="index1309"></a><a name="index1310"></a><a name="index1311"></a><a name="index1312"></a><a name="index1313"></a><a name="index1314"></a><a name="index1315"></a>
See <code>vectors.lsp</code> for a simple implementation of vector arithmetic and other vector functions.
<p>
<a name = "187"><h3>Piano Synthesizer</h3></a>
The piano synthesizer (library name is <code>pianosyn.lsp</code>) generates
realistic piano tones using a multiple wavetable implementation by Zheng (Geoffrey)
Hua and Jim Beauchamp, University of Illinois. Please see the notice about
acknowledgements that prints when you load the file. Further informations and
example code can be found in 
<code>demos/piano.htm</code><a name="index1316"></a><a name="index1317"></a>. 
There are several useful functions in this library. These functions auto-load the 
<code>pianoysn.lsp</code> library if it is not already loaded:
<dl>
<dt>
<code>piano-note(<a name="index1318"></a><a name="index1319"></a><i>duration</i>, <i>step</i>, 
 <i>dynamic</i>)</code> [SAL]<br>

<code>(piano-note <i>duration</i> <i>step</i> <i>dynamic</i>)</code> [LISP]<dd>Synthesizes a piano tone. <i>Duration</i> is the duration to the point of
key release, after which there is a rapid decay. <i>Step</i> is the pitch in half
steps, and <i>dynamic</i> is approximately equivalent to a MIDI key velocity
parameter. Use a value near 100 for a loud sound and near 10 for a soft sound.<br><br>
<dt><code>piano-note-2(<a name="index1320"></a><i>step</i>, <i>dynamic</i>)</code> [SAL]<br>

<code>(piano-note-2 <i>step</i> <i>dynamic</i>)</code> [LISP]<dd>Similar to <code>piano-note</code> except the duration is nominally 1.0.<br><br>
<dt><code>piano-midi(<a name="index1321"></a><i>midi-file-name</i>)</code> [SAL]<br>

<code>(piano-midi <i>midi-file-name</i>)</code> [LISP]<dd>Use the piano synthesizer 
to play a MIDI file. The file name (a string) is given by <i>midi-file-name</i>.<br><br>
<dt><code>piano-midi2file(<a name="index1322"></a><i>midi-file-name</i>, 
<i>sound-file-name</i>)</code> [SAL]<br>

<code>(piano-midi2file <i>midi-file-name</i> <i>sound-file-name</i>)</code> [LISP]<dd>Use the piano synthesizer to play a MIDI file. The MIDI file
is given by <i>midi-file-name</i> and the (monophonic) result is written to the file
named <i>sound-file-name</i>.
</dl>
<p>
<a name = "188"><h3>Dynamics Compression</h3></a>
These functions
implement a compressor originally intended for noisy speech audio, but
usable in a variety of situations.
There are actually two compressors that can be used in 
series. The first, <code>compress</code>, is
a fairly standard one: it detects signal level with an RMS
detector and uses table-lookup to determine how much gain
to place on the original signal at that point. One bit of
cleverness here is that the RMS envelope is "followed" or
enveloped using <code>snd-follow</code>, which does look-ahead to anticipate
peaks before they happen.
<p>
The other interesting feature is <code>compress-map</code>, which builds 
a map in terms of compression and expansion. For speech, the recommended
procedure is to figure out the noise floor on the signal you are compressing
(for example, look at the signal where the speaker is not talking).
Use a compression map that leaves the noise alone and boosts
signals that are well above the noise floor. Alas, the <code>compress-map</code>
function is not written in these terms, so some head-scratching is
involved, but the results are quite good.
<p>
The second compressor is called <code>agc</code>, and it implements automatic gain
control that keeps peaks at or below 1.0. By combining <code>compress</code> and 
<code>agc</code>, you can process poorly recorded speech for playback on low-quality
speakers in noisy environments. The <code>compress</code> function modulates the 
short-term gain to to minimize the total dynamic range, keeping the speech at
a generally loud level, and the <code>agc</code> function rides the long-term gain
to set the overall level without clipping.
<p>
<dl>
<dt>
<code>compress-map(<a name="index1323"></a><i>compress-ratio</i>, 
<i>compress-threshold</i>, 
<i>expand-ratio</i>, <i>expand-threshold</i>, limit: <i>limit</i>, transition: 
<i>transition</i>, verbose: <i>verbose</i>)</code> [SAL]<br>

<code>(compress-map <i>compress-ratio</i> <i>compress-threshold</i>
 <i>expand-ratio</i> <i>expand-threshold</i> :limit <i>limit</i> :transition
 <i>transition</i> :verbose <i>verbose</i>)</code> [LISP]<dd>Construct
a map for the compress function. The map consists of two parts: a compression
part and an expansion part.
The intended use is to compress everything above compress-threshold by
compress-ratio, and to downward expand everything below expand-ratio
by expand-ratio.  Thresholds are in dB and ratios are dB-per-dB.
0dB corresponds to a peak amplitude of 1.0 or rms amplitude of 0.7
If the input goes above 0dB, the output can optionally be limited
by setting <code>limit:</code> (a keyword parameter) to <code>T</code>. 
This effectively changes 
the compression ratio to infinity at 0dB.  If <code>limit:</code> is <code>nil</code>
(the default), then the compression-ratio continues to apply above 0dB.<br><br>
<dt>Another keyword parameter, <code>transition:</code>, sets the amount below the
thresholds (in dB) that a smooth transition starts. The default is 0,
meaning that there is no smooth transition. The smooth transition is a
2nd-order polynomial that matches the slopes of the straight-line compression
curve and interpolates between them.<br><br>
<dt>If verbose is true (this is the default), the map is printed, showing,
for each dB value below zero of this input, what is the gain (in dB) 
indicated by the output. Only regions where the map is changing are 
printed because at lower values, the dB gain is constant.<br><br>
<dt>It is assumed that expand-threshold &lt;= compress-threshold &lt;= 0
The gain is unity at 0dB so if compression-ratio &gt; 1, then gain
will be greater than unity below 0dB.<br><br>
<dt>The result returned by this function is a sound for use in the <code>shape</code>
function. The sound maps input
dB to gain. Time 1.0 corresponds to 0dB, time 0.0 corresponds to
-100 dB, and time 2.0 corresponds to +100dB, so this is a 
100hz "sample rate" sound. The sound gives gain in dB.<br><br>
<dt><code>db-average(<a name="index1324"></a><i>input</i>)</code> [SAL]<br>

<code>(db-average <i>input</i>)</code> [LISP]<dd>Compute the average amplitude 
of <i>input</i> in dB.<br><br>
<dt><code>compress(<a name="index1325"></a><i>input</i>, <i>map</i>, <i>rise-time</i>, <i>fall-time</i> [, <i>lookahead</i>])</code> [SAL]<br>

<code>(compress <i>input</i> <i>map</i> <i>rise-time</i> <i>fall-time</i>
 [<i>lookahead</i>])</code> [LISP]<dd>Compress 
<i>input</i> using <i>map</i>, a compression curve
probably generated by <code>compress-map</code> (see above). Adjustments in gain have
the given <i>rise-time</i> and <i>fall-time</i>. Lookahead tells how far ahead to look
at the signal, and is <i>rise-time</i> by default.<br><br>
<dt><code>agc(<a name="index1326"></a><a name="index1327"></a><a name="index1328"></a><i>input</i>,
<i>range</i>, <i>rise-time</i>, <i>fall-time</i> [, <i>lookahead</i>])</code> [SAL]<br>

<code>(agc <i>input</i> <i>range</i> <i>rise-time</i> <i>fall-time</i>
 [<i>lookahead</i>])</code> [LISP]<dd>An automatic
gain control applied to <i>input</i>. The maximum gain in dB is <i>range</i>. Peaks
are attenuated to 1.0, and gain is controlled with the given <i>rise-time</i> and
<i>fall-time</i>. The look-ahead time default is <i>rise-time</i>.
</dl>
<p>
<a name = "189"><h3>Clipping Softener</h3></a>
This library, in <code>soften.lsp</code>, was written to improve the quality of
poorly recorded speech. In recordings of speech, extreme clipping generates
harsh high frequency noise. This can sound particulary bad on small speakers
that will emphasize high frequencies. This problem can be ameliorated by 
low-pass filtering regions where clipping occurs. The effect is to dull the
harsh clipping. Intelligibility is not affected by much, and the result can
be much more pleasant on the ears. Clipping is detected simply by looking for
large signal values. Assuming 8-bit recording, this level is set to 126/127.
<p>
The function works by cross-fading between the normal signal and a filtered 
signal as opposed to changing filter coefficients.
<p>
<dl>
<dt>
<code>soften-clipping(<a name="index1329"></a><a name="index1330"></a><i>snd</i>, 
<i>cutoff</i>)</code> [SAL]<br>

<code>(soften-clipping <i>snd</i> <i>cutoff</i>)</code> [LISP]<dd>Filter the loud regions of a signal where clipping is likely
to have generated additional high frequencies. The input signal is <i>snd</i>
and <i>cutoff</i> is the filter cutoff frequency
(4 kHz is recommended for speech).
</dl>
<p>
<a name = "190"><h3>Graphical Equalizer</h3></a>
There's nothing really "graphical" about this library (<code>grapheq.lsp</code>), but 
this is a common term for multi-band equalizers. This implementation uses
Nyquist's <code>eq-band</code> function to split the incoming signal into different
frequency bands. Bands are spaced geometrically, e.g. each band could be one
octave, meaning that each successive band has twice the bandwidth. An interesting
possibility is using computed control functions to make the equalization change
over time.
<p>
<dl>
<dt>
<code>nband-range(<a name="index1331"></a><a name="index1332"></a><a name="index1333"></a><i>input</i>, <i>gains</i>, <i>lowf</i>, <i>highf</i>)</code> [SAL]<br>

<code>(nband-range <i>input</i> <i>gains</i> <i>lowf</i> <i>highf</i>)</code> [LISP]<dd>A graphical equalizer applied to 
<i>input</i> (a <code>SOUND</code>). The gain controls and number of bands is given by <i>gains</i>, an
ARRAY of <code>SOUND</code>s (in other words, a Nyquist multichannel <code>SOUND</code>). Any sound in the
array may be replaced by a <code>FLONUM</code>. The bands are
geometrically equally spaced from the lowest frequency <i>lowf</i> to the
highest frequency <i>highf</i> (both are <code>FLONUM</code>s).<br><br>
<dt><code>nband(<a name="index1334"></a><i>input</i>, <i>gains</i>)</code> [SAL]<br>

<code>(nband <i>input</i> <i>gains</i>)</code> [LISP]<dd>A graphical equalizer, identical 
to <code>nband-range</code> with a range of 20 to 20,000 Hz.
</dl>
<p>
<a name = "191"><h3>Sound Reversal</h3></a>
The <code>reverse.lsp</code> library implements functions to play sounds in reverse.
<dl>
<dt>
<code>s-reverse(<a name="index1335"></a><a name="index1336"></a><a name="index1337"></a><a name="index1338"></a><i>snd</i>)</code> [SAL]<br>

<code>(s-reverse <i>snd</i>)</code> [LISP]<dd>Reverses <i>snd</i> (a <code>SOUND</code>). Sound must be shorter
than <code>*max-reverse-samples*</code>, which is currently initialized to 
25 million samples. Reversal allocates about 4 bytes per sample. This function
uses XLISP in the inner sample loop, so do not be surprised if it calls the 
garbage collector a lot and runs slowly. The result starts at the starting
time given by the current environment (not necessarily the starting time 
of <i>snd</i>). If <i>snd</i> has multiple channels, a multiple channel, 
reversed sound is returned.<br><br>
<dt><code>s-read-reverse(<a name="index1339"></a><a name="index1340"></a><i>filename</i>, time-offset: <i>offset</i>, srate: <i>sr</i>, dur: <i>dur</i>, nchans: <i>chans</i>, format: <i>format</i>, mode: <i>mode</i>, bits: <i>n</i>, swap: <i>flag</i>)</code> [SAL]<br>

<code>(s-read-reverse <i>filename</i> :time-offset <i>offset</i>
 :srate <i>sr</i> :dur <i>dur</i> :nchans <i>chans</i> :format <i>format</i> :mode <i>mode</i> 
:bits <i>n</i> :swap <i>flag</i>)</code> [LISP]<dd>This function is 
identical to <code>s-read</code> (see Section ), except it reads 
the indicated samples in reverse. Like
<code>s-reverse</code> (see above), it uses XLISP in the inner loop, so it is slow.
Unlike <code>s-reverse</code>, <code>s-read-reverse</code> uses a fixed amount of 
memory that is independent of how many samples are computed. Multiple channels
are handled. 
</dl>
<p>
<a name = "192"><h3>Time Delay Functions</h3></a>
The <code>time-delay-fns.lsp</code> library implements chorus, phaser, and flange effects.
<p>
<dl>
<dt>
<code>phaser(<a name="index1341"></a><a name="index1342"></a><i>snd</i>)</code> [SAL]<br>

<code>(phaser <i>snd</i>)</code> [LISP]<dd>A phaser effect
applied to <i>snd</i> (a <code>SOUND</code>). There are no parameters, 
but feel free to modify the source code of this one-liner.<br><br>
<dt><code>flange(<a name="index1343"></a><a name="index1344"></a><a name="index1345"></a><i>snd</i>)</code> [SAL]<br>

<code>(flange <i>snd</i>)</code> [LISP]<dd>A flange effect
applied to <i>snd</i>. To vary the rate and other parameters, see the source code.<br><br>
<dt><code>stereo-chorus(<a name="index1346"></a><a name="index1347"></a><i>snd</i>, delay: <i>delay</i>, depth: <i>depth</i>, rate1: <i>rate1</i>, rate2: <i>rate2</i> saturation: <i>saturation</i>)</code> [SAL]<br>

<code>(stereo-chorus <i>snd</i> :delay <i>delay</i> :depth <i>depth</i>
:rate1 <i>rate1</i> :rate2 <i>rate2</i> :saturation <i>saturation</i>)</code> [LISP]<dd>A chorus effect 
applied to <i>snd</i>,
a <code>SOUND</code> (monophonic). The output is a stereo sound with out-of-phase chorus effects applied separately for the left and right channels. See the <code>chorus</code> function below for a description of the optional parameters. The <i>rate1</i> and <i>rate2</i> parameters are <i>rate</i> parameters for the left and right channels.<br><br>
<dt><code>chorus(<a name="index1348"></a><a name="index1349"></a><i>snd</i>, delay: <i>delay</i>, depth: <i>depth</i>, rate: <i>rate</i>, saturation: <i>saturation</i>, phase: <i>phase</i>)</code> [SAL]<br>

<code>(chorus <i>snd</i> :delay <i>delay</i> :depth <i>depth</i> :rate <i>rate</i> :saturation <i>saturation</i> :phase <i>phase</i>)</code> [LISP]<dd>A chorus effect applied to <i>snd</i>. All parameters may be arrays
as usual. The chorus is implemented as a variable delay 
modulated by a sinusoid shifted by <i>phase</i> degrees (a <code>FLONUM</code>) oscillating
at <i>rate</i> Hz (a <code>FLONUM</code>). The sinusoid is 
scaled by <i>depth</i> (a <code>FLONUM</code>. The delayed signal is mixed
with the original, and <i>saturation</i> (a <code>FLONUM</code>) gives the fraction of 
the delayed signal
(from 0 to 1) in the mix. 
Default values are <i>delay</i> 0.03, <i>depth</i> 0.003, <i>rate</i> 0.3, 
 <i>saturation</i> 1.0, and <i>phase</i> 0.0 (degrees).
</dl>
<p>
<a name = "193"><h3>Multiple Band Effects</h3></a>
<a name="index1350"></a><a name="index1351"></a>
The <code>bandfx.lsp</code> library implements several effects based on multiple
frequency bands. The idea is to separate a signal into different frequency
bands, apply a slightly different effect to each band, and sum the effected
bands back together to form the result. This file includes its own set of
examples. After loading the file, try <code>f2()</code>, <code>f3()</code>, <code>f4()</code>,
and <code>f5()</code> to hear them.
Further discussion and examples can be found in 
<code>demos/bandfx.htm</code><a name="index1352"></a>. 
<p>
There is much room for expansion and experimentation with this library. Other
effects might include distortion in certain bands (for example, there are
commercial effects that add distortion to low frequencies to enhance the sound
of the bass), separating bands into different channels for stereo or multi-channel
effects, adding frequency-dependent reverb, and performing dynamic compression, 
limiting, or noise gate functions on each band. There are also opportunities for
cross-synthesis: using the content of bands extracted from one signal to modify
the bands of another. The simplest of these would be to apply amplitude envelopes
of one sound to another. Please contact us (dannenberg@cs.cmu.edu) if you 
are interested in working on this library.
<p>
<dl>
<dt>
<code>apply-banded-delay(<a name="index1353"></a><a name="index1354"></a><i>s</i>, <i>lowp</i>, <i>highp</i>, <i>num-bands</i>, <i>lowd</i>, <i>highd</i>, <i>fb</i>, <i>wet</i>)</code> [SAL]<br>

<code>(apply-banded-delay <i>s</i> <i>lowp</i> <i>highp</i> <i>num-bands</i> <i>lowd</i> <i>highd</i> <i>fb</i> <i>wet</i>)</code> [LISP]<dd>Separates
input <code>SOUND</code> <i>s</i> into <code>FIXNUM</code> <i>num-bands</i> bands from a low frequency
of <i>lowp</i> to a high frequency of <i>highp</i> (these are <code>FLONUMS</code> that specify
steps, not Hz), and applies a delay to each band. The delay for the lowest band is
given by the <code>FLONUM</code> <i>lowd</i> (in seconds) and the delay for the highest band
is given by the <code>FLONUM</code> <i>highd</i>. The delays for other bands are linearly
interpolated between these values. Each delay has feedback gain controlled by
<code>FLONUM</code> <i>fb</i>. The delayed bands are scaled by <code>FLONUM</code> <i>wet</i>, and 
the original sound is scaled by 1 - <i>wet</i>. All are summed to form the result, 
a <code>SOUND</code>.<br><br>
<dt><code>apply-banded-bass-boost(<a name="index1355"></a><a name="index1356"></a><i>s</i>, <i>lowp</i>, <i>highp</i>, <i>num-bands</i>, <i>num-boost</i>, <i>gain</i>)</code> [SAL]<br>

<code>(apply-banded-bass-boost <i>s</i> <i>lowp</i> <i>highp</i> <i>num-bands</i> <i>num-boost</i> <i>gain</i>)</code> [LISP]<dd>Applies a boost to 
low frequencies. Separates
input <code>SOUND</code> <i>s</i> into <code>FIXNUM</code> <i>num-bands</i> bands from a low frequency
of <i>lowp</i> to a high frequency of <i>highp</i> (these are <code>FLONUMS</code> that specify
steps, not Hz), and scales the lowest <i>num-boost</i> (a <code>FIXNUM</code>) bands by <i>gain</i>,
a <code>FLONUM</code>. The bands are summed to form the result, a <code>SOUND</code>.<br><br>
<dt><code>apply-banded-treble-boost(<a name="index1357"></a><a name="index1358"></a><i>s</i>, <i>lowp</i>, <i>highp</i>, <i>num-bands</i>, <i>num-boost</i>, <i>gain</i>)</code> [SAL]<br>

<code>(apply-banded-treble-boost <i>s</i> <i>lowp</i> <i>highp</i> <i>num-bands</i> <i>num-boost</i> <i>gain</i>)</code> [LISP]<dd>Applies a boost to 
high frequencies. Separates
input <code>SOUND</code> <i>s</i> into <code>FIXNUM</code> <i>num-bands</i> bands from a low frequency
of <i>lowp</i> to a high frequency of <i>highp</i> (these are <code>FLONUMS</code> that specify
steps, not Hz), and scales the highest <i>num-boost</i> (a <code>FIXNUM</code>) bands by <i>gain</i>,
a <code>FLONUM</code>. The bands are summed to form the result, a <code>SOUND</code>.
</dl>
<p>
<a name = "194"><h3>Granular Synthesis</h3></a>
Some granular synthesis functions are implemented in the <code>gran.lsp</code> library
file. There are many variations and control schemes one could adopt for granular
synthesis, so it is impossible to create a single universal granular synthesis
function. One of the advantages of Nyquist is the integration of control and
synthesis functions, and users are encouraged to build their own granular synthesis
functions incorporating their own control schemes. The <code>gran.lsp</code> file
includes many comments and is intended to be a useful starting point. Another 
possibility is to construct a score with an event for each grain. Estimate a
few hundred bytes per score event (obviously, size depends on the number of
parameters) and avoid using all of your computer's memory.
<p>
<dl>
<dt>
<code>sf-granulate(<a name="index1359"></a><a name="index1360"></a><i>filename</i>, <i>grain-dur</i>, <i>grain-dev</i>, <i>ioi</i>, <i>ioi-dev</i>, <i>pitch-dev</i>, [<i>file-start</i>, <i>file-end</i>])</code> [SAL]<br>

<code>(sf-granulate <i>filename</i> <i>grain-dur</i> <i>grain-dev</i> <i>ioi</i>
 <i>ioi-dev</i> <i>pitch-dev</i> [<i>file-start</i> <i>file-end</i>])</code> [LISP]<dd>Granular synthesis 
using a sound file
named <i>filename</i> as the source for grains. Grains are extracted from
a sound file named by <i>filename</i> by stepping through the file in equal
increments. Each grain duration is the 
sum of <i>grain-dur</i> and a random number from 0 to <i>grain-dev</i>. Grains are 
then multiplied by a raised cosine smoothing window and resampled at a ratio
between 1.0 and <i>pitch-dev</i>. If <i>pitch-dev</i> is greater than one, grains are
stretched and the pitch (if any) goes down. If <i>pitch-dev</i> is less than one,
grains are shortened and the pitch goes up. Grains are then output
with an 
inter-onset interval between successive grains (which may overlap) 
determined by the sum of
<i>ioi</i> and a random number from 0 to <i>ioi-dev</i>. 
The duration of the resulting sound is determined by
the stretch factor (not by the sound file). The number of grains is
the total sound duration (determined by the stretch factor)
divided by the mean inter-onset interval, 
which is <i>ioi</i> + <i>ioi-dev</i> * 0.5. 
The grains are taken from equally-spaced starting points in <i>filename</i>,
and depending on grain size and number, the grains may or may not overlap.
The output duration will simply be the sum of the inter-onset intervals
and the duration of the last grain. If <i>ioi-dev</i> is non-zero, the
output duration will vary, but the expected value of the duration is
the stretch factor.
To achieve a rich granular synthesis effect, it is often a good idea to
sum four or more copies of <code>sf-granulate</code> together. (See the <code>gran-test</code>
function in <code>gran.lsp</code>.)
</dl>
<p>
<a name = "195"><h3>Chowning FM Voices</h3></a>
John Chowning developed voice synthesis methods using FM to simulate 
resonances for his 1981 composition "Phone." He later recreated the
synthesis algorithms in Max, and Jorge Sastre ported these to SAL. 
See <code>demos/FM-voices-Chowning.sal</code> for more details.
<p>
<a name = "196"><h3>Atonal Melody Composition</h3></a>
Jorge Sastre contributed <code>demos/atonal-melodies.sal</code>, code 
that generates atonal melodies. You can find links to an example
score and audio file in the code and also at
<code>http://algocompbook.com/examples.html</code>.
<p>
<a name = "197"><h3>MIDI Utilities</h3></a>
The <code>midishow.lsp</code> library has functions that can print the contents fo MIDI
files. This intended as a debugging aid.
<p>
<dl>
<dt>
<code>midi-show-file(<a name="index1361"></a><a name="index1362"></a><a name="index1363"></a><i>file-name</i>)</code> [SAL]<br>

<code>(midi-show-file <i>file-name</i>)</code> [LISP]<dd>Print the contents of a MIDI file to the console.<br><br>
<dt><code>midi-show(<a name="index1364"></a><i>the-seq</i> [, <i>out-file</i>])</code> [SAL]<br>

<code>(midi-show <i>the-seq</i> [<i>out-file</i>])</code> [LISP]<dd>Print the
contents of the sequence <i>the-seq</i> to the file <i>out-file</i> (whose default value
is the console.)
</dl>
<p>
<a name = "198"><h3>Reverberation</h3></a>
The <code>reverb.lsp</code> library implements artificial reverberation.
<p>
<dl>
<dt>
<code>reverb(<a name="index1365"></a><a name="index1366"></a><i>snd</i>, 
<i>time</i>)</code> [SAL]<br>

<code>(reverb <i>snd</i> <i>time</i>)</code> [LISP]<dd>Artificial reverberation applied to <i>snd</i> with a decay time of
<i>time</i>.
</dl>
<p>
<a name = "199"><h3>DTMF Encoding</h3></a>
<a name="index1367"></a><a name="index1368"></a>
The <code>dtmf.lsp</code> library implements DTMF encoding. DTMF is the 
"touch tone" code used by telephones.
<p>
<dl>
<dt>
<code>dtmf-tone(<a name="index1369"></a><i>key</i>, <i>len</i>, <i>space</i>)</code> [SAL]<br>

<code>(dtmf-tone <i>key</i> <i>len</i> <i>space</i>)</code> [LISP]<dd>Generate a
single DTMF tone. The <i>key</i> parameter is either a digit (a <code>FIXNUM</code>
from 0 through 9) or the atom <code>STAR</code> or <code>POUND</code>. The duration of
the done is given by <i>len</i> (a <code>FLONUM</code>) and the tone is followed by
silence of duration <i>space</i> (a <code>FLONUM</code>).<br><br>
<dt><code>speed-dial(<a name="index1370"></a><i>thelist</i>)</code> [SAL]<br>

<code>(speed-dial <i>thelist</i>)</code> [LISP]<dd>Generates a sequence
of DTMF tones using the keys in <i>thelist</i> (a <code>LIST</code> of keys as
described above under <code>dtmf-tone</code>). The duration of each tone is 0.2
seconds, and the space between tones is 0.1 second. Use <code>stretch</code> to
change the "dialing" speed.
</dl>
<p>
<a name = "200"><h3>Dolby Surround(R), Stereo and Spatialization Effects</h3></a>
<a name="index1371"></a><a name="index1372"></a><a name="index1373"></a><a name="index1374"></a>
<p>
The <code>spatial.lsp</code> library implements various functions for stereo
manipulation and spatialization. It also includes some functions for
Dolby Pro-Logic panning, which encodes left, right, center, and surround 
channels into stereo. The stereo signal can then be played through
a Dolby decoder to drive a surround speaker array. This library has
a somewhat simplified encoder, so you should certainly test the
output. Consider using a high-end encoder for critical work. There
are a number of functions in <code>spatial.lsp</code> for testing. See the
source code for comments about these.
<p>
<dl>
<dt>
<code>stereoize(<a name="index1375"></a><a name="index1376"></a><a name="index1377"></a><i>snd</i>)</code> [SAL]<br>

<code>(stereoize <i>snd</i>)</code> [LISP]<dd>Convert a mono sound, <i>snd</i>, to stereo. Four bands of 
equalization and some delay are used to create a stereo effect.<br><br>
<dt><code>widen(<a name="index1378"></a><a name="index1379"></a><i>snd</i>, <i>amt</i>)</code> [SAL]<br>

<code>(widen <i>snd</i> <i>amt</i>)</code> [LISP]<dd>Artificially
widen the stereo field in <i>snd</i>, a two-channel sound. The amount of widening
is <i>amt</i>, which varies from 0 (<i>snd</i> is unchanged) to 1 (maximum widening).
The <i>amt</i> can be a <code>SOUND</code> or a number.<br><br>
<dt><code>span(<a name="index1380"></a><a name="index1381"></a><a name="index1382"></a><a name="index1383"></a><i>snd</i>, <i>amt</i>)</code> [SAL]<br>

<code>(span <i>snd</i> <i>amt</i>)</code> [LISP]<dd>Pan the virtual center channel of a stereo sound, <i>snd</i>,
by <i>amt</i>, where 0 pans all the way to the left, while 1 pans all the way 
to the right. The <i>amt</i> can be a <code>SOUND</code> or a number.<br><br>
<dt><code>swapchannels(<a name="index1384"></a><a name="index1385"></a><a name="index1386"></a><i>snd</i>)</code> [SAL]<br>

<code>(swapchannels <i>snd</i>)</code> [LISP]<dd>Swap left and right channels in <i>snd</i>, a stereo sound.<br><br>
<dt><code>prologic(<a name="index1387"></a><a name="index1388"></a><a name="index1389"></a><i>l</i>, <i>c</i>, 
<i>r</i>, <i>s</i>)</code> [SAL]<br>

<code>(prologic <i>l</i> <i>c</i> <i>r</i> <i>s</i>)</code> [LISP]<dd>Encode four monaural <code>SOUND</code>s representing the front-left,
front-center, front-right, and rear channels, respectively. 
The return value is a stereo sound, which is a Dolby-encoded mix of the
four input sounds. <br><br>
<dt><code>pl-left(<a name="index1390"></a><i>snd</i>)</code> [SAL]<br>

<code>(pl-left <i>snd</i>)</code> [LISP]<dd>Produce a Dolby-encoded (stereo)
signal with <i>snd</i>, a <code>SOUND</code>, encoded as the front left channel.<br><br>
<dt><code>pl-center(<a name="index1391"></a><i>snd</i>)</code> [SAL]<br>

<code>(pl-center <i>snd</i>)</code> [LISP]<dd>Produce a Dolby-encoded (stereo)
signal with <i>snd</i>, a <code>SOUND</code>, encoded as the front center channel.<br><br>
<dt><code>pl-right(<a name="index1392"></a><i>snd</i>)</code> [SAL]<br>

<code>(pl-right <i>snd</i>)</code> [LISP]<dd>Produce a Dolby-encoded (stereo)
signal with <i>snd</i>, a <code>SOUND</code>, encoded as the front right channel.<br><br>
<dt><code>pl-rear(<a name="index1393"></a><i>snd</i>)</code> [SAL]<br>

<code>(pl-rear <i>snd</i>)</code> [LISP]<dd>Produce a Dolby-encoded (stereo)
signal with <i>snd</i>, a <code>SOUND</code>, encoded as the rear, or surround, channel.<br><br>
<dt><code>pl-pan2d(<a name="index1394"></a><i>snd</i>, <i>x</i>, <i>y</i>)</code> [SAL]<br>

<code>(pl-pan2d <i>snd</i> <i>x</i> <i>y</i>)</code> [LISP]<dd>Comparable to Nyquist's
existing pan function, <code>pl-pan2d</code> provides not only left-to-right
panning, but front-to-back panning as well. The function
accepts three parameters: <i>snd</i> is the (monophonic) input <code>SOUND</code>, 
<i>x</i> is a left-to-right position, and <i>y</i> is a front-to-back position.
Both position parameters may be numbers or <code>SOUND</code>s. An <i>x</i> value 
of 0 means left, and 1 means right. Intermediate values map linearly
between these extremes. Similarly, a <i>y</i> value of 0 causes the sound
to play entirely through the front speakers(s), while 1 causes it to play
entirely through the rear. Intermediate values map linearly.
Note that, although there are usually two rear speakers in Pro-Logic systems,
they are both driven by the same signal. Therefore any sound that is
panned totally to the rear will be played over both rear speakers. For
example, it is not possible to play a sound exclusively through the 
rear left speaker.<br><br>
<dt><code>pl-position(<a name="index1395"></a><i>snd</i>, <i>x</i>, <i>y</i>, <i>config</i>)</code> [SAL]<br>

<code>(pl-position <i>snd</i> <i>x</i> <i>y</i> <i>config</i>)</code> [LISP]<dd>The
position function builds upon speaker panning to allow more abstract
placement of sounds. Like <code>pl-pan2d</code>, it accepts a (monaural) input
sound as well as left-to-right (<i>x</i>) and front-to-back (<i>y</i>) coordinates,
which may be <code>FLONUM</code>s or <code>SOUND</code>s. A fourth parameter <i>config</i> 
specifies the distance from listeners to the speakers (in meters). Current
settings assume this to be constant for all speakers, but this assumption 
can be changed easily (see comments in the code for more detail).
There are several important differences between <code>pl-position</code> and 
<code>pl-pan2d</code>. First, <code>pl-position</code> uses a Cartesian coordinate 
system that allows x and y coordinates outside of the
range (0, 1). This model assumes a listener position of (0,0). Each speaker
has a predefined position as well. The input sound's position,
relative to the listener, is given by the vector (<i>x</i>,<i>y</i>).<br><br>
<dt><code>pl-doppler(<a name="index1396"></a><a name="index1397"></a><i>snd</i>, 
<i>r</i>)</code> [SAL]<br>

<code>(pl-doppler <i>snd</i> <i>r</i>)</code> [LISP]<dd>Pitch-shift moving sounds according to the equation: <i>fr</i> =
<i>f0</i>((<i>c</i>+<i>vr</i>)/<i>c</i>), where <i>fr</i> is the output frequency, 
<i>f0</i> is the emitted (source) 
frequency, <i>c</i> is the speed of sound (assumed to be 344.31 m/s), and 
<i>vr</i> is the speed at which the emitter approaches the receiver. (<i>vr</i>
is the first derivative of parameter <i>r</i>, the distance from the listener
in meters.
</dl>
<p>
<a name = "201"><h3>Drum Machine</h3></a>
<a name="index1398"></a>
<p>
The drum machine software in <code>demos/plight</code> deserves further explanation. 
to use the software, load the code by evaluating:
<p><pre>
load "../demos/plight/drum.lsp"
exec load-props-file(strcat(*plight-drum-path*, 
                            "beats.props"))
exec create-drum-patches()
exec create-patterns()
</pre></p>

<p>
Drum sounds and patterns are specified in the <code>beats.props</code> file (or
whatever name you give to <code>load-props-file</code>). This file
contains two types of specifications. First, there are sound file specifications.
Sound files are located by a line of the form:
<p><pre>
set sound-directory = "kit/"
</pre></p>

This gives the name of the sound file directory, relative to the 
 <code>beats.props</code> file. Then, for each sound file, there should be a line of
the form:
<p><pre>
track.2.5 = big-tom-5.wav
</pre></p>

This says that on track 2, a velocity value of 5 means to play the sound file
 <code>big-tom-5.wav</code>. (Tracks and velocity values are described below.) 
The <code>beats.props</code> file contains specifications for all the sound files
in <code>demos/plight/kit</code> using 8 tracks. If you make your own specifications
file, tracks should be numbered consecutively from 1, and velocities should be
in the range of 1 to 9.
<p>
The second set of specifications is of beat patterns. A beat pattern is given
by a line in the following form:
<p><pre>
beats.5 = 2--32--43-4-5---
</pre></p>

The number after <code>beats</code> is just a pattern number. Each pattern
is given a unique number. After the equal sign, the digits and dashes are
velocity values where a dash means "no sound." Beat patterns should be
numbered consecutively from 1.
<p>
Once data is loaded, there are several functions to access drum patterns and 
create drum sounds (described below). The <code>demos/plight/drums.lsp</code> file
contains an example function <code>plight-drum-example</code> to play some drums.
There is also the file <code>demos/plight/beats.props</code> to serve as an
example of how to specify sound files and beat patterns.
<p>
<dl>
<dt>
<code>drum(<a name="index1399"></a><i>tracknum</i>, <i>patternnum</i>, <i>bpm</i>)</code> [SAL]<br>

<code>(drum <i>tracknum</i> <i>patternnum</i> <i>bpm</i>)</code> [LISP]<dd>Create
a sound by playing drums sounds associated with track <i>tracknum</i> (a 
FIXNUM) using pattern <i>patternnum</i>. The tempo is given by <i>bpm</i> in
beats per minute. Normally patterns are a sequence of sixteenth notes, so
the tempo is in <i>sixteenth notes per minute</i>. For example,
if <i>patternnum</i> is 10,
then use the pattern specified for <code>beats.10</code>. If the third character
of this pattern is 3 and <i>tracknum</i> is 5, then on the third beat, play
the soundfile assigned to <code>track.5.3</code>. This function returns a <code>SOUND</code>.<br><br>
<dt><code>drum-loop(<a name="index1400"></a><i>snd</i>, <i>duration</i>, <i>numtimes</i>)</code> [SAL]<br>

<code>(drum-loop <i>snd</i> <i>duration</i> <i>numtimes</i>)</code> [LISP]<dd>Repeat the sound given by <i>snd</i> <i>numtimes</i> times. The repetitions occur at a time offset of <i>duration</i>, regardless of the actual duration of <i>snd</i>. A <code>SOUND</code> is returned.<br><br>
<dt><code>length-of-beat(<a name="index1401"></a><i>bpm</i>)</code> [SAL]<br>

<code>(length-of-beat <i>bpm</i>)</code> [LISP]<dd>Given a tempo of 
<i>bpm</i>, return the duration of the beat in seconds. Note that this software
has no real notion of beat. A "beat" is just the duration of each character
in the beat pattern strings. This function returns a <code>FLONUM</code>.
</dl>
<p>


<p>

<p>

<p>

<p>

<p>


<hr>
<a href = "part15.html">Previous Section</a> | <a href = "part17.html">Next Section</a> | <a href = "title.html#toc">Table of Contents</a> | <a href = "indx.html">Index</a> | <a href = "title.html">Title Page</a>
</body></html>
